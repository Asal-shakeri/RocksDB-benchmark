# DevOps Challenge: RocksDB Hash Benchmark

This project implements and documents a benchmarking challenge designed to test how **RocksDB** handles large-scale hash workloads.  
Itâ€™s based on the **â€œProblem of Many Hashesâ€** from the DevOps Challenge, where millions of hash records must be stored, looked up, and updated efficiently.

---

## ğŸ§© Problem Overview

Imagine having:
- 100 million unique hashes stored in a RocksDB database.
- Each day, millions of new hashes arrive â€” some are duplicates, some are new.
- We must check for duplicates (point lookups) and then bulk insert only the unique ones.

This setup creates alternating **read** and **write** phases:
- **Lookup phase** â†’ Random access lookups using `MultiGet`.
- **Ingest phase** â†’ Bulk inserts via SST file ingestion.

Our goal is to evaluate RocksDBâ€™s performance under this workload.

---

## âš™ï¸ Features

- C++ benchmark using the RocksDB native API  
- Bulk load via **SST file ingestion**
- Point lookups via **MultiGet**
- Benchmark configuration options:
  - Database sizes: 1M, 10M, 100M
  - Duplicate ratios: 0%, 25%, 50%, 75%, 100%
  - SST table formats: BlockBased, Plain, Cuckoo
  - Compaction styles: Leveled, Universal
  - Bloom filters: on/off
- Automatically records:
  - Throughput (ops/sec)
  - Average latency (s/op)
  - CPU, memory, and disk usage
  - Final database size

---

## ğŸ§± Project Structure

```
devops-hash-benchmark/
â”œâ”€â”€ README.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ benchmark.cpp
â”‚   â”œâ”€â”€ utils.hpp
â”‚   â””â”€â”€ CMakeLists.txt
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_benchmarks.sh
â”‚   â””â”€â”€ plot_results.py
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ results.csv
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ throughput.png
â”‚       â””â”€â”€ latency.png
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ report.md
â”‚   â””â”€â”€ setup_guide.md
â””â”€â”€ LICENSE
```

---

## ğŸš€ Setup and Execution

### 1. Prerequisites (macOS)
```bash
brew install rocksdb cmake gcc python3
pip3 install matplotlib pandas psutil
```

### 2. Build and Run
```bash
mkdir build && cd build
cmake ..
make
./benchmark
```

### 3. Run Automated Benchmarks
```bash
bash scripts/run_benchmarks.sh
python3 scripts/plot_results.py
```

---

## ğŸ“Š Output

- Raw data saved in: `results/results.csv`
- Plots generated in: `results/plots/`
- Analysis documented in: [`docs/report.md`](docs/report.md)

---

## ğŸ§  Acknowledgments

- **RocksDB Team** â€” for documentation and benchmarking tools  
- **Facebook / Meta Open Source** â€” for RocksDB  
- **OpenAI ChatGPT (GPT-5)** â€” assisted in documentation, design, and automation setup  

---

## ğŸ“š References

- [RocksDB Wiki](https://github.com/facebook/rocksdb/wiki)
- [RocksDB Blog](https://rocksdb.org/blog/)
- [Designing Data-Intensive Applications](https://dataintensive.net/)
- [DevOps Challenge PDF](docs/report.md)
